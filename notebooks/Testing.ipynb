{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "31b90dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ddi.utils import df_optimized, get_data_filepath\n",
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d2a47182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7386395556456596\n",
      "saved model.joblib locally\n",
      "saved pca.joblib locally\n",
      "size_bytes is 169449579\n"
     ]
    }
   ],
   "source": [
    "def get_data():\n",
    "    '''retrieve and clean the final_dataset'''\n",
    "    df = pd.read_csv(get_data_filepath('final_dataset.csv'))\n",
    "    df.drop(columns =[col for col in df.columns if 'Unnamed' in col], inplace = True)\n",
    "    df.drop(columns = ['86'], inplace = True)\n",
    "    df = df_optimized(df)\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    '''transform the df into pca features'''\n",
    "    X = df[df.columns[89:]]  # check with marcus what are X and y columns -\n",
    "    y = df[df.columns[3:89]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3 )\n",
    "\n",
    "    '''scaling_train X'''\n",
    "    std_scaler = StandardScaler()\n",
    "    std_scaler.fit(X_train)\n",
    "    X_train = pd.DataFrame(std_scaler.transform(X_train), columns = X.columns)\n",
    "\n",
    "    '''\n",
    "    pca_transform\n",
    "    NOTE: 80% of the variation can be explained by 47 principal components from param_search.py\n",
    "    '''\n",
    "    pca = PCA(n_components = 47) \n",
    "    pca.fit(X_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "\n",
    "    X_test = std_scaler.transform(X_test)\n",
    "    X_test = pca.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train(X_train,y_train):\n",
    "    '''\n",
    "    train the model\n",
    "    NOTE: unable to use the optimal parameters to train from param_search.py ..\n",
    "    because the size model.joblib was too large for streamlit to process. \n",
    "    '''\n",
    "    forest = RandomForestClassifier(n_estimators=10, random_state=1, criterion= 'gini' )\n",
    "    clf = MultiOutputClassifier(forest, n_jobs = -3)\n",
    "    clf.fit(X_train,y_train)\n",
    "    return clf\n",
    "\n",
    "def test(X_test,y_test):\n",
    "    '''evaluate the model's performance on test data'''\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = 1 - hamming_loss(y_test,y_pred)\n",
    "    print(f\"accuracy: {accuracy}\")\n",
    "    return accuracy\n",
    "\n",
    "def train_full(df):\n",
    "    '''train the model on the full dataset'''\n",
    "    X = df[df.columns[89:]]\n",
    "    y = df[df.columns[3:89]]\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X = std_scaler.fit_transform(X)\n",
    "    pca = PCA(n_components = 60)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    model = train(X,y)\n",
    "\n",
    "    return pca, model\n",
    "\n",
    "def save_model_joblib(model):\n",
    "    '''saving models'''\n",
    "    joblib.dump(model, 'model.joblib', compress = 5)\n",
    "    print(\"saved model.joblib locally\")\n",
    "\n",
    "def save_model_pca(model):\n",
    "    joblib.dump(model,'pca.joblib')\n",
    "    print(\"saved pca.joblib locally\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = get_data()\n",
    "    X_train, X_test, y_train, y_test = preprocess(df)\n",
    "    clf = train(X_train,y_train)\n",
    "    test(X_test,y_test)\n",
    "    pca, model = train_full(df)\n",
    "    save_model_joblib(model)\n",
    "    save_model_pca(pca)\n",
    "    size_bytes = os.stat('model.joblib',).st_size\n",
    "    print(f\"size_bytes is {size_bytes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

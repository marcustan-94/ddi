{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b90dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from ddi.utils import df_optimized, get_data_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2a47182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7386731411347742\n",
      "saved model.joblib locally\n",
      "saved preproc.joblib locally\n",
      "size_bytes is 127048666\n"
     ]
    }
   ],
   "source": [
    "def get_data():\n",
    "    '''retrieve and clean the final_dataset'''\n",
    "    df = pd.read_csv(get_data_filepath('final_dataset.csv'))\n",
    "    df.drop(columns =[col for col in df.columns if 'Unnamed' in col], inplace = True)\n",
    "    df.drop(columns = ['86'], inplace = True) \n",
    "    df = df_optimized(df)\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    '''transform the df into pca features'''\n",
    "    X = df[df.columns[89:]]  # check with marcus what are X and y columns -\n",
    "    y = df[df.columns[3:89]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3 )\n",
    "\n",
    "    '''\n",
    "    creatin a pipeline to process the data\n",
    "    NOTE: 80% of the variation can be explained by 46 principal components from param_search.py\n",
    "    '''\n",
    "    preproc = make_pipeline(StandardScaler(),PCA(n_components =46))\n",
    "    preproc.fit(X_train)\n",
    "    X_train = preproc.transform(X_train)\n",
    "    X_test = preproc.transform(X_test)\n",
    " \n",
    "    return preproc, X_train, X_test, y_train, y_test\n",
    "\n",
    "def train(X_train,y_train):\n",
    "    '''\n",
    "    train the model\n",
    "    NOTE: unable to use the optimal parameters to train from param_search.py ..\n",
    "    because the size model.joblib was too large for streamlit to process. \n",
    "    '''\n",
    "    forest = RandomForestClassifier(n_estimators=10, random_state=1, criterion= 'gini' )\n",
    "    clf = MultiOutputClassifier(forest, n_jobs = -3)\n",
    "    clf.fit(X_train,y_train)\n",
    "    return clf\n",
    "\n",
    "def test(X_test,y_test):\n",
    "    '''evaluate the model's performance on test data'''\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = 1 - hamming_loss(y_test,y_pred)\n",
    "    print(f\"accuracy: {accuracy}\")\n",
    "    return accuracy\n",
    "\n",
    "def train_full(df):\n",
    "    '''train the model on the full dataset'''\n",
    "    X = df[df.columns[89:]]\n",
    "    y = df[df.columns[3:89]]\n",
    "\n",
    "    std_scaler = StandardScaler()\n",
    "    X = std_scaler.fit_transform(X)\n",
    "    pca = PCA(n_components = 46)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    model = train(X,y)\n",
    "\n",
    "    return pca, model\n",
    "\n",
    "def save_model_joblib(model):\n",
    "    '''saving models'''\n",
    "    joblib.dump(model, 'model.joblib', compress = 3)\n",
    "    print(\"saved model.joblib locally\")\n",
    "\n",
    "def save_preproc(model):\n",
    "    '''saving prepoc model'''\n",
    "    joblib.dump(model,'preproc.joblib')\n",
    "    print(\"saved preproc.joblib locally\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = get_data()\n",
    "    preproc, X_train, X_test, y_train, y_test = preprocess(df)\n",
    "    clf = train(X_train,y_train)\n",
    "    test(X_test,y_test)\n",
    "    save_model_joblib(clf)\n",
    "    save_preproc(preproc)\n",
    "    size_bytes = os.stat('model.joblib',).st_size\n",
    "    print(f\"size_bytes is {size_bytes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "435b88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit import Chem\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "\n",
    "from ddi.utils import get_data_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e39993e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  7.72it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'preproc.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     89\u001b[0m     model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAspirin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mParacetamol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mclassify\u001b[0;34m(drug1, drug2, model)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify\u001b[39m(drug1, drug2, model):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;124;03m'''Converts the predicted class numbers into names of classes predicted'''\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrug1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrug2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# A dictionary is created that returns the predicted sub_system as values\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     y_dict \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(Y_class\u001b[38;5;241m.\u001b[39msub_system_severity\u001b[38;5;241m.\u001b[39mvalues, index \u001b[38;5;241m=\u001b[39m Y_class\u001b[38;5;241m.\u001b[39mY_cat)\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(drug1, drug2, model)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m'''Predicts the target class numbers from the input drug combination'''\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Features dataframe is built\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mpreproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrug1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrug2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Model is used to predict the target class numbers\u001b[39;00m\n\u001b[1;32m     64\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mpreproc\u001b[0;34m(drug1, drug2)\u001b[0m\n\u001b[1;32m     51\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mabs()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# PCA is performed to reduce the dimensionality of the differenced features\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m preproc \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreproc.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m X_test \u001b[38;5;241m=\u001b[39m preproc\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_test\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/ddi/lib/python3.8/site-packages/joblib/numpy_pickle.py:579\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    577\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'preproc.joblib'"
     ]
    }
   ],
   "source": [
    "Y_class = pd.read_csv(get_data_filepath('complete_severity_reclassification.csv'),\n",
    "                      usecols = ['sub_system_severity','Y_cat'])\n",
    "Y_class = Y_class[(Y_class['Y_cat'] != 86)]\n",
    "\n",
    "# Mordred calculates over 1300 molecular features of the drugs, but as only 721\n",
    "# features used for prediction (feature column names are reflected in feat_eng_df)\n",
    "feat_eng_df = pd.read_csv(get_data_filepath('feature_engineering.csv'), nrows=0)\n",
    "X_cols = feat_eng_df.columns[1:]\n",
    "\n",
    "\n",
    "def get_smiles(drug1,drug2):\n",
    "    '''Converts drug names to smiles structures, returns try again\n",
    "    error if the drug names cannot be converted by the API\n",
    "    '''\n",
    "    smile_list = []\n",
    "    for drug in [drug1,drug2]:\n",
    "        try:\n",
    "            url = 'http://cactus.nci.nih.gov/chemical/structure/' + quote(drug) + '/smiles'\n",
    "            ans = urlopen(url).read().decode('utf8')\n",
    "            smile_list.append(ans)\n",
    "        except:\n",
    "            smile_list.append('Unable to find the drug, please try again.')\n",
    "\n",
    "    return smile_list\n",
    "\n",
    "\n",
    "def get_mordred(drug1, drug2):\n",
    "    '''Calculates the molecular features of the drugs from their\n",
    "    smile structures and builds them into a dataframe\n",
    "    '''\n",
    "    # Drug names are converted into smiles through API\n",
    "    smile_list = get_smiles(drug1, drug2)\n",
    "\n",
    "    # Molecular features dataframe is built from the smile list provided\n",
    "    mols = [Chem.MolFromSmiles(item) for item in smile_list]\n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    drug_features = calc.pandas(mols)\n",
    "    return drug_features\n",
    "\n",
    "\n",
    "def preproc(drug1, drug2):\n",
    "    '''Extracts features from the drug names into a dataframe, and perform scaling and PCA transformation'''\n",
    "    drug_features = get_mordred(drug1, drug2)\n",
    "    # Booleans in the dataframe are converted into numbers 0 and 1\n",
    "    drug_features.replace({False: 0, True: 1}, inplace=True)\n",
    "    # Filter out only the necessary 721 columns\n",
    "    drug_features = drug_features[X_cols]\n",
    "    # Features are differenced to calculate the similarity of molecular features between the drug pair\n",
    "    X_test = pd.DataFrame(drug_features.iloc[0] - drug_features.iloc[1]).transpose()\n",
    "    # Obtaining absolute values as we are only interested in the magnitude of the difference between features\n",
    "    X_test = X_test.abs()\n",
    "    # PCA is performed to reduce the dimensionality of the differenced features\n",
    "    preproc = joblib.load('preproc.joblib')\n",
    "    X_test = preproc.transform(X_test)\n",
    "\n",
    "    return X_test\n",
    "\n",
    "\n",
    "def predict(drug1, drug2, model):\n",
    "    '''Predicts the target class numbers from the input drug combination'''\n",
    "    # Features dataframe is built\n",
    "    X_test = preproc(drug1, drug2)\n",
    "    # Model is used to predict the target class numbers\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def classify(drug1, drug2, model):\n",
    "    '''Converts the predicted class numbers into names of classes predicted'''\n",
    "    y_pred = predict(drug1, drug2, model)[0]\n",
    "    # A dictionary is created that returns the predicted sub_system as values\n",
    "    y_dict = pd.Series(Y_class.sub_system_severity.values, index = Y_class.Y_cat).to_dict()\n",
    "\n",
    "    # The predicted classes are retrieved and stored into a list'''\n",
    "    prediction_list = []\n",
    "    for i, x in enumerate(y_pred):\n",
    "        if x == 0:\n",
    "            continue\n",
    "        prediction_list.append(i)\n",
    "\n",
    "    # The predicted side effects are retrieved given the predicted categories'''\n",
    "    side_effect_list = []\n",
    "    for i in prediction_list:\n",
    "        side_effect_list.append(y_dict[i])\n",
    "\n",
    "    return side_effect_list\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = joblib.load('model.joblib')\n",
    "    print(classify('Aspirin','Paracetamol', model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda30aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
